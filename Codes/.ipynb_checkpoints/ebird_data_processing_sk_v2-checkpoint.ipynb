{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Processing ebird data with geopandas and vectorization for performance"
      ],
      "metadata": {
        "id": "jaek3SZIZXb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas shapely\n",
        "!pip install --upgrade pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ipjgikXaErX",
        "outputId": "4e55e505-b535-4aaf-cad4-9defd57adbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.6 pandas-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# required imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, LineString\n",
        "from shapely.ops import nearest_points\n",
        "import logging\n",
        "from typing import Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xnuIuwn9Z1Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "r-eVV4Kfa8SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xELlMyJEZ8ar",
        "outputId": "41d53a93-c985-49f5-e875-d3c77f1ca308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Capstone/ebd_US-DC-001_201901_202505_relApr-2025.zip'"
      ],
      "metadata": {
        "id": "Xdgg4wWsaux8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add code to view file names from zip path"
      ],
      "metadata": {
        "id": "1hfrl9pBbPx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_to = \"extracted_files\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extract(\"ebd_US-DC-001_201901_202505_relApr-2025.txt\", extract_to)"
      ],
      "metadata": {
        "id": "EFFIwC1dbLDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the extracted file\n",
        "ebird_dc_df = pd.read_csv(\"/content/extracted_files/ebd_US-DC-001_201901_202505_relApr-2025.txt\", sep='\\t')\n",
        "\n",
        "# # Assign zone index to each detection\n",
        "# ebird_dc_df[\"zone_index\"] = ebird_dc_df.apply(\n",
        "#     lambda row: assign_zone_to_point(row[\"LONGITUDE\"], row[\"LATITUDE\"], zones), axis=1\n",
        "# )\n",
        "\n",
        "# # Save to CSV\n",
        "# ebird_dc_df.to_csv(\"/content/drive/MyDrive/Capstone/ebd_US-DC-001_201901_202505_relApr-2025.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "4QscQe_9bgFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "ebird_dc_df.to_csv(\"/content/drive/MyDrive/Capstone/filtered_ebd_US-DC-001_201901_202505.csv\", index=False)"
      ],
      "metadata": {
        "id": "TzcCQghmcs5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebird_dc_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKFtRzrDcAO9",
        "outputId": "711a0087-be3b-4c42-83d0-138a53046951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2003460, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = [\n",
        "    'COMMON NAME', 'SCIENTIFIC NAME', 'OBSERVATION COUNT', 'COUNTRY', 'STATE', 'COUNTY',\n",
        "    'LOCALITY', 'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE',\n",
        "    'TIME OBSERVATIONS STARTED', 'DURATION MINUTES'\n",
        "]\n",
        "ebird_dc_df = ebird_dc_df[columns_to_keep]"
      ],
      "metadata": {
        "id": "8nFRzlxgdRYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i95 coordinates processing"
      ],
      "metadata": {
        "id": "k4_U2lswe4xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i95_coordinates = pd.read_csv('/content/drive/MyDrive/Capstone/i95_modified.csv')\n",
        "i95_sorted = i95_coordinates.sort_values(['Overall_Sequence'])\n",
        "i95_coords = list(zip(i95_sorted['Latitude'], i95_sorted['Longitude']))"
      ],
      "metadata": {
        "id": "GKeLdTrne8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWufiQHmZEu7"
      },
      "outputs": [],
      "source": [
        "#\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class OptimizedBatchProcessor:\n",
        "    \"\"\"\n",
        "    Heavily optimized processor using GeoPandas, spatial indexing, and vectorized operations\n",
        "    Expected 10-100x performance improvement over original implementation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_file: str = \"/content/drive/MyDrive/Capstone/filtered_ebd_US-DC-001_201901_202505.csv\",\n",
        "                 output_file: str = \"/content/drive/MyDrive/Capstone/filtered_DC.csv\",\n",
        "                 batch_size: int = 100000,\n",
        "                 distance_threshold: float = None,\n",
        "                 i95_coords: list = None):\n",
        "\n",
        "        self.input_file = input_file\n",
        "        self.output_file = output_file\n",
        "        self.batch_size = batch_size\n",
        "        self.distance_threshold = distance_threshold\n",
        "\n",
        "        # Pre-process I-95 coordinates into optimized spatial structures\n",
        "        self._setup_highway_geometry(i95_coords)\n",
        "\n",
        "        # Statistics tracking\n",
        "        self.total_rows_processed = 0\n",
        "        self.total_rows_saved = 0\n",
        "        self.batch_count = 0\n",
        "\n",
        "    def _setup_highway_geometry(self, i95_coords):\n",
        "        \"\"\"Convert I-95 coordinates to optimized spatial structures\"\"\"\n",
        "        if not i95_coords:\n",
        "            raise ValueError(\"I-95 coordinates must be provided\")\n",
        "\n",
        "        logger.info(\"Setting up highway geometry with spatial indexing...\")\n",
        "\n",
        "        # Create LineString geometry from coordinates\n",
        "        self.highway_line = LineString([(lon, lat) for lat, lon in i95_coords])\n",
        "\n",
        "        # Create GeoDataFrame for the highway with spatial index\n",
        "        highway_gdf = gpd.GeoDataFrame([1], geometry=[self.highway_line], crs='EPSG:4326')\n",
        "\n",
        "        # Convert to projected CRS for accurate distance calculations (US National Grid)\n",
        "        self.highway_gdf_projected = highway_gdf.to_crs('EPSG:3857')  # Web Mercator for speed\n",
        "        self.highway_line_projected = self.highway_gdf_projected.geometry.iloc[0]\n",
        "\n",
        "        logger.info(\"Highway geometry setup complete\")\n",
        "\n",
        "    def calculate_distances_vectorized(self, obs_gdf: gpd.GeoDataFrame) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Vectorized distance calculation using GeoPandas\n",
        "        This is the key optimization - processes all points at once\n",
        "        \"\"\"\n",
        "        # Project observations to same CRS as highway\n",
        "        obs_projected = obs_gdf.to_crs('EPSG:3857')\n",
        "\n",
        "        # Vectorized distance calculation to highway line\n",
        "        distances_meters = obs_projected.geometry.distance(self.highway_line_projected)\n",
        "\n",
        "        # Convert meters to miles\n",
        "        distances_miles = distances_meters * 0.000621371\n",
        "\n",
        "        return distances_miles.values\n",
        "\n",
        "    def process_batch_optimized(self, batch_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Optimized batch processing using vectorized operations\"\"\"\n",
        "\n",
        "        # Filter out rows with invalid coordinates early\n",
        "        valid_coords = batch_df.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "\n",
        "        if len(valid_coords) == 0:\n",
        "            logger.warning(\"No valid coordinates in batch\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Convert to numeric and filter realistic coordinate ranges\n",
        "        valid_coords = valid_coords.copy()\n",
        "        valid_coords['LATITUDE'] = pd.to_numeric(valid_coords['LATITUDE'], errors='coerce')\n",
        "        valid_coords['LONGITUDE'] = pd.to_numeric(valid_coords['LONGITUDE'], errors='coerce')\n",
        "\n",
        "        # Filter to reasonable coordinate bounds (roughly continental US)\n",
        "        coord_filter = (\n",
        "            (valid_coords['LATITUDE'].between(24, 50)) &\n",
        "            (valid_coords['LONGITUDE'].between(-130, -65))\n",
        "        )\n",
        "        valid_coords = valid_coords[coord_filter]\n",
        "\n",
        "        if len(valid_coords) == 0:\n",
        "            logger.warning(\"No valid coordinates after filtering\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Create GeoDataFrame from observations\n",
        "        geometry = [Point(lon, lat) for lon, lat in\n",
        "                   zip(valid_coords['LONGITUDE'], valid_coords['LATITUDE'])]\n",
        "        obs_gdf = gpd.GeoDataFrame(valid_coords, geometry=geometry, crs='EPSG:4326')\n",
        "\n",
        "        # Calculate distances using vectorized operation\n",
        "        distances = self.calculate_distances_vectorized(obs_gdf)\n",
        "\n",
        "        # Add distances to dataframe\n",
        "        result_df = valid_coords.copy()\n",
        "        result_df['i95_distance'] = distances\n",
        "\n",
        "        # Apply distance filter if specified\n",
        "        if self.distance_threshold is not None:\n",
        "            result_df = result_df[result_df['i95_distance'] <= self.distance_threshold]\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    def _process_one_batch(self, batch_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Process a single batch with logging\"\"\"\n",
        "        self.batch_count += 1\n",
        "        self.total_rows_processed += len(batch_df)\n",
        "\n",
        "        logger.info(f\"Processing batch {self.batch_count} with {len(batch_df)} rows\")\n",
        "\n",
        "        processed_batch = self.process_batch_optimized(batch_df)\n",
        "        self.total_rows_saved += len(processed_batch)\n",
        "\n",
        "        logger.info(f\"Batch {self.batch_count}: {len(batch_df)} -> {len(processed_batch)} rows\")\n",
        "\n",
        "        return processed_batch\n",
        "\n",
        "    def run_pipeline(self) -> dict:\n",
        "        \"\"\"Run the complete optimized pipeline\"\"\"\n",
        "        logger.info(f\"Starting optimized pipeline: {self.input_file}\")\n",
        "        logger.info(f\"Batch size: {self.batch_size}\")\n",
        "        logger.info(f\"Distance threshold: {self.distance_threshold}\")\n",
        "\n",
        "        all_processed_data = []\n",
        "\n",
        "        try:\n",
        "            # Process in chunks with larger batch size\n",
        "            chunk_iter = pd.read_csv(self.input_file, chunksize=self.batch_size)\n",
        "\n",
        "            for chunk in chunk_iter:\n",
        "                processed_chunk = self._process_one_batch(chunk)\n",
        "                if not processed_chunk.empty:\n",
        "                    all_processed_data.append(processed_chunk)\n",
        "\n",
        "            # Combine and save results\n",
        "            if all_processed_data:\n",
        "                final_df = pd.concat(all_processed_data, ignore_index=True)\n",
        "                final_df.to_csv(self.output_file, index=False)\n",
        "                logger.info(f\"Saved {len(final_df)} rows to {self.output_file}\")\n",
        "            else:\n",
        "                logger.warning(\"No data to save\")\n",
        "                final_df = pd.DataFrame()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Pipeline error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'total_rows_processed': self.total_rows_processed,\n",
        "            'total_rows_saved': self.total_rows_saved,\n",
        "            'total_batches': self.batch_count,\n",
        "            'output_file': self.output_file,\n",
        "            'filter_efficiency': (self.total_rows_saved / self.total_rows_processed * 100)\n",
        "                                if self.total_rows_processed > 0 else 0\n",
        "        }\n",
        "\n",
        "        logger.info(\"Optimized pipeline completed!\")\n",
        "        logger.info(f\"Statistics: {stats}\")\n",
        "        return stats\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file: str = \"/content/drive/MyDrive/Capstone/filtered_ebd_US-DC-001_201901_202505.csv\",\n",
        "output_file: str = \"/content/drive/MyDrive/Capstone/filtered_DC.csv\","
      ],
      "metadata": {
        "id": "YRPqJtyUgHWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    processor = OptimizedBatchProcessor(\n",
        "        input_file=\"/content/drive/MyDrive/Capstone/filtered_ebd_US-DC-001_201901_202505.csv\",\n",
        "        output_file=\"/content/drive/MyDrive/Capstone/filtered_DC.csv\",\n",
        "        batch_size=100000,\n",
        "        distance_threshold=25,\n",
        "        i95_coords=i95_coords\n",
        "    )\n",
        "\n",
        "    results = processor.run_pipeline()\n",
        "    print(\"Optimized processing complete!\")\n",
        "    print(f\"Results: {results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KREN6EHgf2J4",
        "outputId": "be494cc5-0c68-46e4-a57d-3d93ae40717f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized processing complete!\n",
            "Results: {'total_rows_processed': 2003460, 'total_rows_saved': 2003460, 'total_batches': 21, 'output_file': '/content/drive/MyDrive/Capstone/filtered_DC.csv', 'filter_efficiency': 100.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.read_csv(\"/content/drive/MyDrive/Capstone/filtered_DC.csv\")"
      ],
      "metadata": {
        "id": "DMgRa1kzgqCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6kraJ0ElZU4",
        "outputId": "2f2ac3af-260e-42cd-a77f-325f835a19b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2003460, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7FI0zSqlb-K",
        "outputId": "c72ec759-050a-467f-a55d-46eac8d48800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['COMMON NAME', 'SCIENTIFIC NAME', 'OBSERVATION COUNT', 'COUNTRY',\n",
              "       'STATE', 'COUNTY', 'LOCALITY', 'LATITUDE', 'LONGITUDE',\n",
              "       'OBSERVATION DATE', 'TIME OBSERVATIONS STARTED', 'DURATION MINUTES',\n",
              "       'i95_distance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.i95_distance.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "5Dj9gaTblhJ5",
        "outputId": "f44da6f0-d70e-454e-a8d5-0c2264ed391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "i95_distance\n",
              "0.086041    314712\n",
              "1.715896    205746\n",
              "0.010148    147701\n",
              "0.059427    137707\n",
              "0.011724     84115\n",
              "             ...  \n",
              "0.029660         1\n",
              "0.045132         1\n",
              "0.055755         1\n",
              "0.001420         1\n",
              "0.048369         1\n",
              "Name: count, Length: 13762, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i95_distance</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.086041</th>\n",
              "      <td>314712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.715896</th>\n",
              "      <td>205746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.010148</th>\n",
              "      <td>147701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.059427</th>\n",
              "      <td>137707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.011724</th>\n",
              "      <td>84115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.029660</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.045132</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.055755</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.001420</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.048369</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13762 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}